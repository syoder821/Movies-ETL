# Movies-ETL
Challenge project purpose is to gather movie data from both Wikipedia and Kaggle, combine them, and save them into a SQL database in order to have a clean dataset to use. To do this, the ETL process is used: extract the Wikipedia and Kaggle data from their respective files, transform the datasets by cleaning them up and joining them together, and load the cleaned dataset into a SQL database.
To support keeping the database updated on a daily basis an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables is created. One function is created that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.
